0:01 - mirowengner
want to do this, but there is no available information how they progress with it. And I don't know if you know something more.

0:15 - Glenn Renfro
Well, there's a couple things going on and this is where I'm kind of curious as to where that particular... Hey, Vlad, how are you doing?

0:24 - Vlad
Good to see you.

0:24 - Glenn Renfro
So, there's a couple of things. And I know that Spring is working on one where it's not Spring-centric, it's actually Java-centric in their views on what they found on it. And I know they're working on that. But Pratik wants to kind of take another dig at it from a different direction. So he's setting up a repo that he wants to go over. So we're shooting for the 20th on that talk. They'll be able to pop in on that.

0:59 - Vladimir Sonkin
Hello, Vladimir. Hello, Catalin. Hello, Glenn. Hello, everyone.

1:09 - Glenn Renfro
Everybody, the classic professor, five minute late. So everybody has a chance to jump in, even though our professor is here already, to give the talk. He was on time. It's the students that are late. We're gonna wait for them to come on in. But it's exciting times, exciting times, my friends. Daniel, I know you more, started live clips from this last week. I saw a few that were just hilarious. So I was like, oh gosh, I gotta send these to Daniel.

1:44 - mirowengner
Glenn, do you have some particular terms as information about how Spring would love to approach the benchmarking in Jaffa? Because this is essentially very hard topic. I know it seems sly, but this kind of benchmark.

1:58 - Glenn Renfro
Yes, that is a good question. You know what I want to do is let me do this. The person leading efforts, a gentleman named Mark Pollack. I'm going to reach out to him, see where he's at on that topic. Yeah, and see what they're at. And I may report that as like a like a five minute preview to. Critiques thing, but I'll cover critiques. I'll make sure I don't step on his toes. I want to make sure I'm sensitive to that as well because he's working hard on it too. So, but I mean, it just is, you know, again, it could be just a comparison contrast to see if the two styles are different and just to see which direction they're going. It would be very interesting. Oh, absolutely.

2:42 - mirowengner
Because, you know, basically current benchmarks are off topic. I wouldn't rely on on these benchmarks because they are very executed on very simple scenarios, which are not referring to the way how AI is used. Even with the kind of very cool research I have reported from right now into the AI news from the Google meta and so on, these benchmarks wouldn't say they are useless. But they need to be taken from very careful understanding was how they are, was the actual concept.

3:25 - Glenn Renfro
One of the things that Mark was talking about was that it's also that they, a lot of the benchmarking doesn't take in like, you know, basic static analysis and some of the other things that we have to use. And a lot of them are like, okay, did it solve the problem? Yeah, sort of, but it, Did, you know, all we got like in that one case that we talked about, where it's like, okay, Italy, it said, did the test pass yes or no? Well, or did it answer the, well, did they, did they just get a passing grade or did they actually answer the problem, the test, because it keeps the test blind. Is that a valid benchmark? Is one of the questions I'm like, well, I don't think so.

4:08 - mirowengner
Just a couple of articles I Read like recently, they are done on current state of the art of LLMs. Basically, LLMs or agent and multiple agent systems and so on, they are achieving with slightly complex, not with not complex problems to solve with code migration on code writing, they are achieving around 50% success, including the test.

4:34 - Glenn Renfro
Unless it's a one that's been trained on Python, then if we test against Java comes in, oh, Java only has a 12% success.

4:45 - mirowengner
70% Java is slightly, slightly, I mean, less successful due to the type safety. But that's a difference. It's like a 10%. It's not really significant. And the the concept of it a slightly advanced model and other techniques where they recommend the agent Yeah, it doesn't matter if this is over the caches or tech space and so on. So they are achieving like 60%. So it's from my perspective. It's like company are barring money in super high scale. Like it's like getting the maximum speed.

5:33 - Glenn Renfro
Yeah, absolutely. Well, folks, I'm gonna go ahead and And we're going to reintroduce Vladimir Sonkin, and he is our guide. He is our teacher, our professor today. And I appreciate everybody who's jumping in. We are recording this session and getting transcripts for those folks that cannot make it today. We most welcome them. I will have these notes available out this evening. And, well, I don't know, me and Prateek may be a little busy on some other stuff tonight. It might be tomorrow before they get out, but nonetheless, I will get them out the next day or so. I'm going to turn it over to Vladimir. Go for it, my friend.

6:14 - Vladimir Sonkin
Thank you. Thank you, Glenn. Just one moment. I will start sharing the presentation. I will shortly remind you the things we have discussed a long time ago in the and time one month is a huge period of time. We have discussed Jake and maybe not everyone has participated so I will shortly remind you. So Jake is the system I am working on. Deterministic AI code generator and what is the main idea is that okay we are able to use LLMs for and agents like cursor agent or many other agents of this kind for code generation. But agents are somehow chaotic. Yes, they are generating the code, but every time when they generate it, we don't know exact steps. And every time it generates it in a little bit different way. And with Jake, we are able to make it in more organized way like orchestration yes so we have define we pre-define the exact steps we pre-define the validation steps and okay jig allows to implement the code generation which could be completely automatic why it could be achieved yes with ai agent we are having more creativity and flexibility But for enterprise applications, it's often necessary to have more predictable results, more reliable results, and to implement the complete automation. So, and one of the main reasons why we need to do it is that agents, in many cases, are leading to architecture drift. For sure, there are many approaches to avoid this kind of architectural drift. For sure, we're able to create knowledge base, we're able to validate the code, to create architectural tests. So many, many ways how it could be done. But JIG suggests completely different approach. And this is the results from the recent poll about the usage of AI in the enterprise. This is meta study in July, 2025. And I I don't know, I don't believe actually, because I'm extensively use AI for code generation, and I believe still that it increases their performance. But this study here, I will be able to share the link later, but maybe you have heard about this study. This study tells that actually the real speed of development has decreased maybe maybe for bigger projects maybe for really complicated cases but so the expectation is that it will increase but reality is that it decreases and one of the reasons that AI introduces chaos to our code base and this is the thing we are trying to to handle to manage and And one way to manage it is to divide ourselves, not to delegate. Yes, so agent is able to divide the task to the subtasks and create to-do lists, do everything of this kind. But when we delegate it, we are not completely, it is not reliable process. It is not predictable process and it controlled process. With orchestration, it could be more controllable, reliable. We are able to predefine the exact steps. And as Java developers, you should know, for example, that the creating standard application, Spring application, consists of many standard steps like generate entities, generate DTOs. Either we are writing it manually or we are able to generate them, generate interfaces, implementations. And if we are going step by step, this process is more predictable. And this approach, this manual definition of what is the workflow, is applicable not only to the software, but also it could be applied to the process of writing an article or preparing for the talk, for example. Idea, then we need to find the sources, we are able to create the table of contents, write the first part, and what is very important that we need to introduce the validation steps, like validate the correctness of grammar, validate the correctness of factual check, and make updates. And this is iterative process. This is iterative process standard workflow, which we follow as the humans. And the same iterative process could be followed it by AI. If we are using AI agent this iterative process is also used yes by contemporary agents but this process is not strictly predefined yes it is a little bit different every time so it depends it depends you know if you if you are using agents you know that every time it creates a little bit different process and our system could be more rigid. Yes, rigid is not very good, but for enterprise generation, for predictability, it could have some advantages. And if we rely on multi-step process, it's important to have very high level of reliability, because even if we have reliability, I mean that the results of each step step should be of high quality yes because the next step relies on the results of the previous step and even if the reliability is relatively high yes know 90 is very high reliability for ai based code generation if we create the flow the sequence of prompts containing for example 10 steps and each step has 90% reliability, the overall reliability will be only 0.9 power of 10. And it will be only 0.35, which is 35% unacceptable reliability, yes. And we may name it a butterfly effect, yes, when the small mistake in the beginning of the process leads to complete of the final result. So we are able to split the process, we are able to add validators in every step. This is what we discussed here a month ago, in September, more than a month ago. Okay, these things I will skip. So, with improvisation, with normalization, agents this is like a Pandora box yes and we don't know every time what will be extracted by the agent yes so it is it is chaotic its house in many cases leads to the proper proper solutions but it's unpredictable yes and with orchestration we are able to provide exact steps which are So jig is justified AI generator. Why it is justified? Because it is justified by the process and allows to build repeatable assembly line. Yes, like conveyor. Justified by evidence because it introduces automatic checks, like validation steps. Every step after running every step, we are running the validation And if validation do not pass, then we're able to repeat this step until all validations will pass. So for example, for writing article, we are validating the grammar and make corrections, validating the factual check, maybe many other validations. And for generating the code, it could be even compilation, running tests. All these things also executed by agent. But again, it is less predictable in case of agents. Okay, okay, okay, okay. Okay, this thing. And one another many important idea behind jig is that, okay, we are creating the prompt pipeline. Yes, we are creating the sequence of the prompts. And this sequence of the prompts allow us to generate something here, then go further, further, further and further. But what another thing we are thinking? So we have usually some process, process of creating some artifact. Yes, in our case, process of preparing the code of the project. And we are able to split it in multiple steps. But also the same process is applicable to different use cases, to different business yes, requirements. And this clear separation of what we need to do and how we need to do it, yes, is another one key idea behind Jake, yes, because here, if we create the requirements and if we take the predefined pipeline of the code, we're able to regenerate the code. For example, we are able to take same requirements and regenerate and apply the same requirements to another workflow. Or we can take the same workflow and use it with different sets of requirements. And if we are changing requirements, we are just regenerating. And from this idea, we have another, another new innovation of jQuery and it is treating code as artifact, yes, regeneratable artifact. Like in CICD, yes, in deployments, this is very long time, for very long time. It's normal that we are not changing anything, we are regenerating. Yes, for example, we have Docker file, we have Kubernetes, and everything is regenerated. So the code is also disposable artifact. And it could be completely regenerated with a little bit changed workflow or a little bit changed requirements. And it means that our main interest should be in requirements, not in the code itself. Code is the resulting artifact and our main interest here. And I would say that this separation is somehow similar to how Spring, when it was introduced, separated code from configuration, yes? Because in Spring, okay, we have the code, and we extracted all the configuration from the code, and it made code much more flexible, yes? We're able to build different applications based on the same codebase, but with a little bit different configuration. And the same approach could be, not the same, but somehow similar, yes similar philosophy of separation yes could be applied to Jake yes because in Jake we separate the prompt pipeline from the requirements and we are able to regenerate the code yes and code could be different okay so in Jake clearly separates what to do from how to do it yes so what to do is defined in the specification uh and we name this specification jiggle like jake language and this is the way how we formalize the system yes it is unambiguous this is key think that it should not have any ambiguity yes execute executable business logic so this is natural language basically but it is formalized natural language. And we will discuss it. This is our main topic today. And another one thing is PPL. Stands for Prompt Pipeline Language. This is the language which describes prompts. First step, second step, third step. This defines how we build the software. So this is what we want to build. This is how we're building it. And instead of fetching the code, So this is one of the key principles and consequences of the overall architecture that code is a temporary artifact. So we are taking the jiggle, we are taking PPL and we are regenerating the code. Code is not the source of truth anymore. Code is not pitched. So you know that main problems arise when we are patching the code, and this terrible architectural drift happens, yes, when we are patching, patching here, patching there, and the complicated code becomes unsupportable, and something goes wrong in most of the cases. And instead of patching the code, instead of changing the existing code, you know, agents like GitHub or Courser agents are patching the code mostly, but our approach is to completely regenerate code and it makes architectural drift impossible. Okay, and one another thing that we're able to create the repository of the workflows. Yes, we are able to take the same application and apply different workflows. For example, we're able to implement the application based on Spring Boot or next time we want to do the same but with another flow for example we want to generate Python application or we want to generate Node.js application anything yes we you just need to select the proper workflow and we should have the repository of the workflow similar to Maven yes you take the library from the repository, but the same, you can have the repository of prompt pipelines. This is the idea. And the developer role shifts from the performer to catalyst, yes, and okay, instead of manually implementing every step, we are just creating the automated pipelines, the process, the process of running our prompts. And our main topic for the discussion today will be JGL, the specification. So what is JGL? Is a language for formal structured natural language. It is like programming language, but it is expressed in natural English, yes, and with Jagle we are able to write logic in plain English, and the idea is that it could be converted without any ambiguity to any programming language, and there is no matter now which programming language you are using. Language now is like machine code you don't know and you don't mind what kind of processor your application will be working on yes and the same for jiggle you will be writing everything you will describe everything in natural language and this natural language will be converted into programming language one or another no matter which one because programming language will be intermediate format it will be not final format and then from this intermediate representation like java for example it will be converted into machine code finally by compiler yes so we have these three steps natural language which we are using now to formulate algorithms and requirements and everything else yes and then then it it is converted to any programming language. And JAGL is a structured readable language that looks like English, but is a formal enough for automation. And these are some examples. This is a traditional code and this how it could be expressed in JAGL. So this is like specification language. This is not something really new because there are many discussions nowadays about specification based development Yes, spec-based development. Recently, GitHub also presented some tool for this kind of development. So, but what is the idea behind our Jagle approach? That we are able to formulate the initial, initial request, initial idea, and then Jague is able to ask for clarifying questions like, okay, when the user places owner, check it, each item is in stock, but this initial user input has lack of precision, yes? It could be treated in different ways, which is unacceptable for code generation. And the most important here is process of asking clarifying questions. We are able to ask this or that question. And finally, after all this clarification, when the system, when AI don't see any ambiguity in our purposes, it generates the final specification, which could be directly converted to any programming language. So, and we Okay, if we need to change the requirements. So the idea that we shouldn't manually change even JGL, yes? So not only that we don't need to manually write programming language code, we even don't need to write specification manually. We are providing our draft input to the system, okay? We want to change requirements this way. And then we go through the process of clarifications, clarification process. And after that, the jiggle definition is automatically updated. And our purpose is just to validate, is it corresponds what we expected or not? If not, then we again introduce some change. So, this language could be presented in different formats, not only as the plain English, but it could be presented as the diagrams. For example, this is the simple way how we can present it as the diagram. And each JAGL algorithm should be executable, simulatable, visualizable. For example, for example, via plant UML and testable. Finally, JGL should represent some bricks in the bigger knowledge base. So knowledge base describes everything. Knowledge base describes what are the purposes of the system, what are the models of the system. In JGL is the language for algorithms within this knowledge base, which defines all the details how the algorithm should be Okay, and jagle provides some kind of recipes for the knowledge base. Yes, and jagle definitions become reusable building blocks or recipes. So instead of functions or methods, define recipes in jagle. And finally, the idea is that we take jagle specification, apply jiggle to the pipeline and then we get the final code generated final code yes so pipeline prompt pipeline takes requirements expressed in jiggle and generates the final code and the usually we don't need to frequently change the pipeline pipeline should be stable it it could be changed sometimes but you Usually the process of how we generate the code is more or less stable. So the most important place where we're changing something is JGL itself. Okay, so this is comparison with JGL. So our purpose, first of all, we need to populate knowledge base, then we generate JGL, and finally we generate the code. Okay, so, okay, this, this, I will skip. So, jiggle together with knowledge base implements the complete vision of the system. Jiggle recipes together with knowledge base rules, relationships, facts, everything, yes. Okay, so, jiggle plays like a bridge between humans and intelligent systems, and it makes English the new source of truth. And this way we are able to communicate with stakeholders, with domain experts much easier, yes, because we don't anymore concentrate on the code in any programming language. We don't need to learn any programming language. We should probably to have the complete control. But usually if you're Compiling language to, for example, to assembly. You don't need to understand all the details how assembly work. Sometimes for very rare cases you need, but in most cases and most of the application developers, business developers do not need to understand all the details how your code from high level language is compiled into low level language. Streamline automation. You are able to completely automate process of generation. So in general, we just need to provide the jiggle, and then we generate code. This is the core idea. And okay, to summarize, we have started from the chaotic agents, and our purpose is to go up to code beauty, speed, and access. And these are the summary of what I have explained. The core problem is that AI assistants, AI agents, are leading to architectural drift, and it's difficult to use it for the bigger projects. Philosophy is that it is justified, it is verified, it is orchestrated and trustworthy process. Core mechanics is the separation. Of what to do and express in JGL and how to do it in prompt pipeline language. And consequence is that we are treating code as a disposable artifact and the outcome, the developer role shifts from performer to catalyst. So this is the summary. And now let me demonstrate my draft implementation. It's on the early stage, but uh I I will try to demonstrate you okay let me make this bigger okay I already have demonstrated it a month ago but it was on the earlier stage of development and now let me so uh basically we are able to take the project I will remind you what we we already have demonstrated previous time. So we have the project, this is our requirements. And for example, here we have the definition of, this is configuration of our system, yes? Like a link to the requirements, variables defined for our system, like the name of the package to generate. And this is the specification of the system, like Jagle specification. And again, this is the workflow and we have the pipeline for example this is the first step to generate the basic basic classes the basic tools and okay these variables you see for example package name is taken from the from here com.example.library yes and it is it is set here so we can preview that it is it is And if we are satisfied with this substitution, we're able to press run button and it is starting to generate the code. For example, here it is generating pomxml first. This is initial code of the system. Based on this configuration. So requirements is included. So everything is generated. You can see here, we see the generated files application. Yaml, application Java, pomxml. So, and, okay, then we are able to go to the next step and this is validation, validation process. In every prompt, this common context is included automatically. And it includes things like package name, project name, requirements, everything. And requirements is taken from here. This is the requirements. So the finally, for example, For example, project structure, this is first prompt in our pipeline. And the final representation of this prompt is that it includes many things, including requirements. Yes, these requirements are set here, and it is set to the system for generation. And here, for example, we have validator, it is validating the previous step and checking if everything has passed successfully. And it returns either OK or not OK. OK, generation OK, validation OK. And it means that we are able to go to the next step and, for example, generate GP entities. And on the next step, we are taking the requirements and we're generating, depending on our Use case, our use case today will be creating a library. It is creating the entities. It is creating one, two entities, book, author, reader. It is generating everything. And okay, as soon as it is generated, yes, we can preview it. Everything is generated and we are able to go further and generate repositories. Okay, so and the next steps are able to rely on previous steps. So we have the prompt pipeline and it is strictly predefined. But okay, that's enough. These things I already demonstrated on previous presentation of this tool. So I will clear. Internally, all the files are stored in virtual file system in the browser. This is the complete virtual file system. Within the browser, you can see everything here. I will clean it up. Clear VFS. And okay, now I have cleaned up all the system. And now I will start demonstrate you how we can build the requirements. This is the purpose of today. And for this purpose, I will open Jagle Studio. This is the new thing. And in Jagle Studio, we are able to define the new document I will define it I will describe it as library and I will describe initial requirements create we are going to generate our description of our system create a library management management system okay create a library library management system. I've pressed create document and it is starting to generate clarifying questions. Clarifying questions. What user roles should the system support? I am able to select, for example, librarian. And here I am able to see the details, manage the catalog, checks books in and out and handles member queries. And probably member. Can browse the catalog, out books. These are my answers. Then how should books be checked in and out? Manual barcode RFID. I can see the details about the question. This is the detailed explanation. Now, how should the book catalog be maintained? Manually and automated. The system will... Here I'm able to type in any answer in the free format. These are just available options to simplify the process, yes, to speed up the process. Okay, manual, librarians will manually enter and update book information. Okay, I select manual. What types of, as soon as I answer the next question, the new questions are get generated. Yes, you can see it is generating a little bit more questions in advance, but the previous questions are based on the next question. This is one of the core ideas, that when the new questions are generated, they are taking the details already answered in the previous questions, and they depend on the previous questions. Not the next one, but the next questions will be generated, because AI receives not only the initial requirement, but also it receives all my answers, and it is generating more and more clarifying questions. Okay, I am continuing. What types of search filters do you need? Okay, title, author, that's enough. What user authentication methods should be supported? Username, password, that's enough. What types of notifications should the system send? Overdue, notice. I can select not needed, for example. If no need in notifications from the system, I'm pressing Not Needed. What borrowing rules should be implemented for users? What does it mean? Users can borrow any number of books without restriction. Let's do it this way. Should the system handle your date reminders? Should the system support book reservations? We can implement. If the system should support reservation, additional functionality will be needed to allow users to reserve books that are currently Okay, let's do it. What level of access should different user roles have to book catalog? Okay, users... What level of access? View only. Users can only view catalog without making changes. I think this is correct. Should the system track and display dual dates? Okay, and so on. This is endless list. Maybe not endless, there is a mechanism inside internal mechanism which is able to stop it when AI decides that everything is clarified it will complete this process but it can take enormous time it it may require maybe hundred equations to be answered and I'm able to break at any moment and click this GenerateSpecification is generated asynchronously. I am able to continue answering the questions. Okay, but Specification is ready. Oops, where is... Okay, I will generate it again. This is some... Just one moment. Okay, this is Specification, and I'm able to see the first draft specification based on my answers, based on the things which I, of how I have answered. And you can see now I can check this answer and I can edit it. For example, I have set that, okay, we have two roles, a librarian and member, and I can change it. For example, from member, I can change to patron. I can change some details I can I can somehow clean it up everything yes so this is the description I am able to edit it I am able to continue answering questions and I am able to regenerate at any next moment yes for example I don't like this I want to continue answering and I am able to get back and and continue clarification process. And then on any I am able to generate specification again. So for example, okay, all these questions are already answered, but these questions are not answered yet. And this is endless list. Should the system support book renewals? Okay, maybe yes. And if I continue to answer about it, the new version of regenerated specification will already include something about book renewals, because system will get this response in addition to the previous responses. And this is the new regenerated. And you can see book renewals is included now. Allow members to renew borrowed books as needed. Now I have two options. Either I can open this specification in jig. And in this case, it will be used as okay, I will show it. Okay, it is taken and here a library jiggle, it contains the current specification, or otherwise, I'm able to continue clarification. What does mean continue clarification, it takes the generated specification. And now I'm able to name it, for example, stage two. And now it is generating the questions based on the previous specification, the first stage of specification. So stage two, again, asking me some clarification questions, but it already knows everything what has been decided in this, what have been described in this specification. Receives not only the initial request, but now for stage two, it receives the specification of stage one. Yes, so it is the drift specification. And now I am able to continue answering. What method of authentication should be used for library management system? Okay, what additional search filters be implemented? Okay, not needed, for example. What permissions should differ between librarians and members? Okay, what does it mean? Clarify if checking in books is a librarian-only function. Checking in books may be not only checkout books, reserve books, view catalog, What should be managed catalog should be different, yes. Renew books, maybe two. Okay, what will be the access method to members to view only access to view catalog? Okay, web. How should the borrowing and return process be initiated? Check-in, check-out desk, online portal. Okay, maybe online portal and so on. And then I'm able to generate specification again, But this is already the second stage of specification. So, and it is based on the first version of specification. And now with more, more, more detailed clarifications. I am able to take a look. This is, you can see it is more detailed document. And it contains much more things like glossary, again, the list of actors, but now it contains more detailed about functional requirements, user authentication and acceptance criteria, happy path, given a registered user when they enter correct credentials, search functionality, book reservations, book renewals. So user stories, it contains user stories, it contains acceptance criteria. And again, I'm able to open it in JIG or I can continue clarification on the second stage three. And this is third stage this is the third stage from the point of view of detail of how detailed is the specification but actually where this is the mistake you can see there are still alpha alpha version there are some bugs it should be in not stage two stage three it should be just stage three but okay what authentication method should be used for user login. Username, password. What type of notification should be used to confirm a book reservation? What method of notification should be used to confirm a book reservation? What search filters should be available? Title and author search filters. What preferences should member have for reservation? And so on. I am able to generate This is the final third stage, maybe not final. Theoretically, we're able to continue, but the format of specification has three steps. Yes, the minimal detail, minimally detailed, moderate details and maximal details in stage three. The specification is generated. It is maximally detailed. For sure, non-functional requirements, it contains business rules. It's already includes business rules. Yes, because here we didn't have business rules on stage two. We didn't have, you see, only the functional requirements, but here we already have business rules. Not only user stories, but business rules. And I now will open it in Jig. These longer requirements. Requirements is open it in JIG and I'm able to select workflow. I will not be using Spring workflow. I will use specification workflow and demonstrate you what documents may be derived from these requirements. And first of all, I will generate you that we're able to generate the list of actors. Let me show you. I will press run and it is generating list of actors. As it was described in our system. Librarian, and this is the definition, librarian is responsible for maintaining the book catalog within the library management system. Member, individual who interacts with library management system. Online portal. Okay, then I'm able to generate, for example, user stories. Okay, it is based on requirements and actors. I will generate it. Okay, librarian. This is basically it is just extracted because we had already user stories in our requirements. I am able to see it. And here I am able, I am already have these two documents. I'm able, for example, for user stories, I'm able to click edit and I'm able to edit it. And this is the user stories, librarian. User authentication. It is a little bit more detailed. Manual book management as a librarian I want to manually manage book check-ins and checkouts yes this is editable I am able to save it at any moment and it will be used as the basis for the next generations member user user this is this describes all the processes now I am able to generate a glossary glossary is the vocabulary of our system okay key terms like librarian member authenticator catalog, all the terms. This is the ubiquitous language of our system. So every, every term is defined here. Now I will generate the use case diagram for our system. It is generating the diagram in plant UML. This is the prompt. This is the prompt. And this is the process of generation. You can see prompt requirements and output is use cases. And this is the diagram I am able to open it here use cases diagram and preview and this is the generated diagram member what what are their capabilities of member renew books reserve books borrow books librarian what what is able what librarian is able to do yes okay for sure we're able to open it and edit it the next thing we're able generate CLI specification. What is the idea here? That we are able to generate the description of the system. This is like, if our application was used as the common line interface application, what should be, how it should be looking like, Later, based on this CLI prototype, we are able to generate demo application, initial application, to present it, for example, to the domain experts or potential end users. So we're able to generate this prototype and it defines the menu and the actions. This is like user interface. How the user interface would be looking like, Let me open it here. CLI specification edit. And this is menu of our system. We have, this is the menu, library management system member, the menu for the member, for like what member is able to do. Member is able to log in, and this is the description. What will happen if user wants to log in? Okay, this is description. This is behavior. Prompts user for username and password. Verifies credentials. Grants access. Search books. This is the capability. Check out books. Again, based on our answers. And this is the librarian menu. What librarian is able to do? Manual book check-in, view catalog, all the capabilities of librarian. Okay, then we're able to generate a class diagram. This is the diagram of classes. For sure, these things have to be refined. And this is, as I said, still alpha version and initial draft of the system. But at least this is the demonstration of philosophy and ideology of the system. Okay, let me open generated file. And in our case, we have, okay, this is generated. Oh, this is some mistake because I don't know. It generated not P-U-M-L. It may happen sometimes. You can see there is no validation what it generated and it generated instead of PUML file it generated txt and json let me try again it happens maybe next time it will generate you see now it generates domain model PUML let me open it I don't know domain model P-UML. For some reason, I cannot demonstrate it, but you can see it generated the plant UML, but it is saving it to the wrong file. Sorry for that. And finally, I will demonstrate you the generation of HTML prototype. This is the last thing. I already have little time left. So what is HTML prototype? This is implementation, again, of the user interface to better understand the features and behavior of our system. And with this prototype, you're able to see the potential behavior of the system. Okay, this is prototype preview. And okay, this is the menu of our system. This is user authentication. We're able to see what, oops, what are the capabilities of the system. Yes, renewals, catalog. Not everything is working properly yet, yes, but for some reason it opens here. Oops, oops, oops. But anyway, these generate, I will open it just in the, in the editor. Let me, let me open it right here. So this is roto HTML, just to show you how it should be working proto. And I will open it just, just to show it completely because something with the visualization. So we are able to switch. This is our system. This is the system, not system, the prototype of the system generated based on a, our answers based on our requirements, yes? So we are able to check in book, check out book, these are capabilities, yes? Book management, search, okay, this is what we are able to search. Borrowing process, reservations, catalog, this is the list of all the books in the catalog. In more complicated cases, it is able to generate even the prototype of this kind, yes, you can see. Prototype is very advanced prototype it's also have been generated based on our requirements about library yes and for example this is the catalog of the books we are able to filter out please find me only available books this is not the real application this is the fake application but it is generated to demonstrate the process and my idea next idea is to integrate this prototype with the feedbacks to the requirements yes for example we are browsing this prototype and right here we should be able to provide the feedbacks and these feedbacks could be used to change the requirements yes and we we preview and okay we are able you can see we can renew okay limit reached for example it is even interactive in this case we're able this book sapiens It's a brief history of humankind. We're able, this is calls and reservations. I am able to cancel reservation, for example. I don't want this book anymore. Okay, hold, cancel it. And it is even removed. Self-checkout return, we're able to, this is like scanning barcode. Librarian circulation, view account. This is all details about patron. This is ID of the member, library member. We can see all the active loans, all the books by this member and all the wait list. So this is the overall user interface, which allows to much better understand the purposes of the system. So this is the demo. This is the initial state of the system for sure. And everything is just published just before for this presentation, I have published everything, uploaded everything to GitHub, and you can find here the description of the system. You can find here how to install it locally. It is open source, you can try, and it includes an extensive documentation. You can Read much more about the philosophy, the approaches, the internal architecture, architecture, everything of this kind. So I will share this link. And you are welcome to take a look and to join in the process of development, everything. Thank you. That's it. Thank you, Vladimir.

59:39 - Glenn Renfro
Thank you for sharing that with us. Folks, we are at time. But if you have questions, certainly I think you can raise a question through GitHub to Vladimir. And again, just thank you for presenting today. It was an interesting topic. I have questions I'm going to probably ask you offline. Is there a way which we can ask? Is there, beside GitHub, that we could ask questions to you?

1:00:08 - Vladimir Sonkin
You can use my email. So I'm in the mailing list. Or I'm using WhatsApp, Telegram, so you can find me on the messengers team.

1:00:24 - Glenn Renfro
I do appreciate it, folks. Look forward to seeing y'all. If y'all are going to join us for the Java AI General Group on dash, not dashboarding, but on benchmarking, look forward to seeing y'all next week. And for the rest, just have a wonderful week. Take care, folks. Thank you, Glenn. Thank you. Thank you.

1:00:44 - Glenn Renfro
Bye bye.

1:00:45 - Unidentified Speaker
Thank you.
